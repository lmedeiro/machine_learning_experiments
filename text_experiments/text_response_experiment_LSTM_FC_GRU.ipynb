{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-rc1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)  # Ensure that we're using \"2.0.0-rc1\"\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as k\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as metrics\n",
    "import pdb\n",
    "from pdb import set_trace as bp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: \n",
    "This notebook builds on [this tensorflow tutorial](https://www.tensorflow.org/tutorials/text/text_generation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mmodels\u001b[0m/                             stock_exchange.txt\r\n",
      "nyc_stock_exchange.txt              text_response_experiment_0.ipynb\r\n",
      "principles_of_plitical_economy.txt  text_response_experiment_RNN_CNN.ipynb\r\n",
      "stock_exchange_from_within.txt\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg EBook of Principles Of Political Economy by John\r\n",
      "Stuart Mill\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "This eBook is for the use of anyone anywhere at no cost and with almost no\r\n",
      "restrictions whatsoever. You may copy it, give it away or re-use it under\r\n",
      "the term\n",
      "Length of text: 1504941 characters\n"
     ]
    }
   ],
   "source": [
    "text = open('principles_of_plitical_economy.txt', 'rb').read().decode(encoding='utf-8')\n",
    "# text += open('stock_exchange.txt', 'rb').read().decode(encoding='utf-8')\n",
    "# text += open('nyc_stock_exchange.txt', 'rb').read().decode(encoding='utf-8')\n",
    "# text += open('stock_exchange_from_within.txt', 'rb').read().decode(encoding='utf-8')\n",
    "print(text[:250])\n",
    "print ('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 unique characters\n",
      "['\\n', '\\x0c', '\\r', ' ', '!', '\"', '#', '$', '%', '&', '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '£', '§', '¼', '½', '¾', 'É', '×', 'à', 'â', 'ä', 'æ', 'ç', 'è', 'é', 'ê', 'î', 'ô', 'ö', 'ü', 'Œ', 'ε', 'η', 'ι', 'ρ', 'ς', 'σ', 'τ', 'φ', 'χ', 'ω', 'ά', 'ύ', 'ῆ', '—', '‘', '’', '“', '”', '™']\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "print ('{} unique characters'.format(len(vocab)))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping the strings to a numerical representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1504941,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_int.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = plt.hist(text_as_int, bins=len(vocab), density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  '\\n':   0,\n",
      "  '\\x0c':   1,\n",
      "  '\\r':   2,\n",
      "  ' ' :   3,\n",
      "  '!' :   4,\n",
      "  '\"' :   5,\n",
      "  '#' :   6,\n",
      "  '$' :   7,\n",
      "  '%' :   8,\n",
      "  '&' :   9,\n",
      "  '(' :  10,\n",
      "  ')' :  11,\n",
      "  '*' :  12,\n",
      "  '+' :  13,\n",
      "  ',' :  14,\n",
      "  '-' :  15,\n",
      "  '.' :  16,\n",
      "  '/' :  17,\n",
      "  '0' :  18,\n",
      "  '1' :  19,\n",
      "  ...\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('{')\n",
    "for char,_ in zip(char2idx, range(20)):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
    "print('  ...\\n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'The Project G' ---- characters mapped to int ---- > [54 71 68  3 50 81 78 73 68 66 83  3 41]\n"
     ]
    }
   ],
   "source": [
    "# Show how the first 13 characters from the text are mapped to integers\n",
    "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T\n",
      "h\n",
      "e\n",
      " \n",
      "P\n"
     ]
    }
   ],
   "source": [
    "# The maximum length sentence we want for a single input in characters\n",
    "seq_length = 150\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "  print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'The Project Gutenberg EBook of Principles Of Political Economy by John\\r\\nStuart Mill\\r\\n\\r\\n\\r\\n\\r\\nThis eBook is for the use of anyone anywhere at no cost and '\n",
      "'with almost no\\r\\nrestrictions whatsoever. You may copy it, give it away or re-use it under\\r\\nthe terms of the Project Gutenberg License included with thi'\n",
      "'s eBook or\\r\\nonline at http://www.gutenberg.org/license\\r\\n\\r\\n\\r\\n\\r\\nTitle: Principles Of Political Economy\\r\\n\\r\\nAuthor: John Stuart Mill\\r\\n\\r\\nRelease Date: Septe'\n",
      "'mber 27, 2009 [Ebook #30107]\\r\\n\\r\\nLanguage: English\\r\\n\\r\\nCharacter set encoding: UTF-8\\r\\n\\r\\n\\r\\n***START OF THE PROJECT GUTENBERG EBOOK PRINCIPLES OF POLITICAL'\n",
      "' ECONOMY***\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n                     Principles Of Political Economy\\r\\n\\r\\n                                    By\\r\\n\\r\\n                             J'\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "  print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: (151,), types: tf.int64>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((150,), (150,)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'The Project Gutenberg EBook of Principles Of Political Economy by John\\r\\nStuart Mill\\r\\n\\r\\n\\r\\n\\r\\nThis eBook is for the use of anyone anywhere at no cost and'\n",
      "Target data: 'he Project Gutenberg EBook of Principles Of Political Economy by John\\r\\nStuart Mill\\r\\n\\r\\n\\r\\n\\r\\nThis eBook is for the use of anyone anywhere at no cost and '\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 54 ('T')\n",
      "  expected output: 71 ('h')\n",
      "Step    1\n",
      "  input: 71 ('h')\n",
      "  expected output: 68 ('e')\n",
      "Step    2\n",
      "  input: 68 ('e')\n",
      "  expected output: 3 (' ')\n",
      "Step    3\n",
      "  input: 3 (' ')\n",
      "  expected output: 50 ('P')\n",
      "Step    4\n",
      "  input: 50 ('P')\n",
      "  expected output: 81 ('r')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 150), (64, 150)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 100000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM, FC, and GRU Model\n",
    "\n",
    "The model below is an experiment to verify performance of an LSTM layer, a consecutive dimension reduction with FC, followed by a GRU. Finally, adding and merging the GRU with an FC layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCNNModel(k.Model):\n",
    "    def __init__(self, \n",
    "                 vocab_size, \n",
    "                 embedding_dim, \n",
    "                 rnn_units, \n",
    "                 batch_size,\n",
    "                fc_reduction_output_shape,\n",
    "                ):\n",
    "        super(LSTMCNNModel, self).__init__()\n",
    "        self.embedding_0 = k.layers.Embedding(vocab_size, \n",
    "                                              embedding_dim,\n",
    "                                              batch_input_shape=[batch_size, None])\n",
    "        self.rnn_0 = k.layers.LSTM(rnn_units, \n",
    "                                  return_sequences=True,\n",
    "                                  stateful=True,\n",
    "                                  recurrent_initializer='glorot_uniform')\n",
    "        self.rnn_1 = k.layers.GRU(rnn_units, \n",
    "                                  return_sequences=True,\n",
    "                                  stateful=True,\n",
    "                                  recurrent_initializer='glorot_uniform')\n",
    "        self.fc_reduction_0 = k.layers.Dense(units=rnn_units,\n",
    "                                          activation='relu')\n",
    "        self.fc_reduction_1 = k.layers.Dense(units=embedding_dim,\n",
    "                                          activation='relu')\n",
    "        self.d_0 = k.layers.Dense(vocab_size, activation=None)\n",
    "        \n",
    "\n",
    "    def call(self, x, labels=None):\n",
    "        x = self.embedding_0(x)\n",
    "        x_lstm = self.rnn_0(x)\n",
    "        x_fc_reduction = self.fc_reduction_0(x_lstm)\n",
    "        x_fc_reduction = self.fc_reduction_1(x_fc_reduction)\n",
    "        x = tf.add(x_lstm, x_gru)\n",
    "        x = self.d_0(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(input_data,\n",
    "               target_data,\n",
    "               model,\n",
    "               optimizer, \n",
    "               train_loss_container,):\n",
    "    with tf.device('gpu'):\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(input_data)\n",
    "            # bp()\n",
    "            loss = tf.reduce_mean(\n",
    "                tf.keras.losses.sparse_categorical_crossentropy(target_data,\n",
    "                                                                predictions, \n",
    "                                                                from_logits=True))\n",
    "#             loss = tf.reduce_mean(\n",
    "#                 tf.keras.losses.MSE(target_data, predictions))\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        train_loss_container.append(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 150\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, \n",
    "                  num_generate=1000):\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "\n",
    "    # Number of characters to generate\n",
    "    num_generate = num_generate\n",
    "\n",
    "    # Converting our start string to numbers (vectorizing)\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    # We must have the same batch size, as we stipulated in the model build. \n",
    "    input_data = np.zeros([BATCH_SIZE, len(input_eval)], dtype=np.int32)\n",
    "    input_data[0] += input_eval\n",
    "    # Empty string to store our results\n",
    "    text_generated = []\n",
    "    \n",
    "    # Low temperatures results in more predictable text.\n",
    "    # Higher temperatures results in more surprising text.\n",
    "    # Experiment to find the best setting.\n",
    "    temperature = 1.0\n",
    "\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_data)[0]\n",
    "        # using a categorical distribution to predict the word returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        # We pass the predicted word as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = [predicted_id]\n",
    "        input_data = np.zeros([BATCH_SIZE, len(input_eval)], dtype=np.int32)\n",
    "        input_data[0] += input_eval\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('gpu'):\n",
    "    optimizer = k.optimizers.Adam(learning_rate=0.001, \n",
    "                              epsilon=1e-07)\n",
    "    train_loss_container = []\n",
    "    model = LSTMCNNModel(vocab_size, embedding_dim,\n",
    "                         rnn_units, BATCH_SIZE,\n",
    "                        fc_reduction_output_shape=[rnn_units, embedding_dim])\n",
    "    EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 1.1451473236083984\n",
      "What about economics ?. And A Schäxigsts;\n",
      "      “Listion,” and in failuriets a settible,” pp. 32-1881, HalD (Loney was\n",
      "of one ground are petellible as wanth of it was det\n",
      "Epoch 1 Batch 100 Loss 1.1512558460235596\n",
      "What about economics ?\n",
      "\n",
      "  206 See Chart No. XIII Trae, at Duth without 2 be faim that the view returns he ex they were from\n",
      "    the production of lo supply. The equipata\n",
      "Epoch 1 Loss 1.1016\n",
      "Time taken for 1 epoch 41.59588408470154 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.0808122158050537\n",
      "What about economics ?\n",
      "\n",
      "Perish (as completeived lastlese marriage to unrast them in the four offerianied by sext,\n",
      "    he can erect for demand, second escepted) of labor)\n",
      "Epoch 2 Batch 100 Loss 1.041778564453125\n",
      "What about economics ?. Of a tax on Everything the office\n",
      "    nt the two, constanths of a country to productive essential value by a\n",
      "    translation or rice; toow, which \n",
      "Epoch 2 Loss 1.0600\n",
      "Time taken for 1 epoch 41.9690842628479 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.0408868789672852\n",
      "What about economics ?\n",
      "\n",
      "  410 “Leption of Wages duties on the poeres, and which\n",
      "    like Elempland its ctrimious price; while iinstalch for to the\n",
      "    production of the\n",
      "Epoch 3 Batch 100 Loss 1.0593924522399902\n",
      "What about economics ?.\n",
      "\n",
      "  333 Cooder, more does not present, the exchange, but\n",
      "    industries\n",
      "the reason of the name of wealth which, by the first increase of populati\n",
      "Epoch 3 Loss 1.0714\n",
      "Time taken for 1 epoch 41.541112422943115 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.0213128328323364\n",
      "What about economics ?\n",
      "    of himself: the people. Nor his deposits will receiving\n",
      "    in the circulation of his deposit, a tax on which must really\n",
      "    then we accomfor\n",
      "Epoch 4 Batch 100 Loss 1.0170702934265137\n",
      "What about economics ?\n",
      "      4,497,387                3b\n",
      "    13    94\n",
      "1521              .550.           .5875          58,000\n",
      "1877           2,215, and the banker, in m\n",
      "Epoch 4 Loss 1.0620\n",
      "Time taken for 1 epoch 41.73340392112732 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.003983736038208\n",
      "What about economics ?\n",
      "\n",
      "    A. Walker.\n",
      "\n",
      "\n",
      "\n",
      "§ 1. the circumstances which first being risen in their\n",
      "state, but to which work all the number of the horse of importing l\n",
      "Epoch 5 Batch 100 Loss 1.0100454092025757\n",
      "What about economics ?\n",
      "\n",
      "  232 per cent of high portion of population. See Nown\n",
      "    avail, and the amount of the houity actually fund among that mers\n",
      "natural instance. A\n",
      "Epoch 5 Loss 1.0170\n",
      "Time taken for 1 epoch 41.68819785118103 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.9148131012916565\n",
      "What about economics ?\n",
      "\n",
      "  359 (Lanue Chap. X1) Aastri,\n",
      "             are, the commonly is condition  $17), that is, really certities\n",
      "on the startation of fixade, most ex\n",
      "Epoch 6 Batch 100 Loss 0.9969071745872498\n",
      "What about economics ?.Fon those in the books\n",
      "of credit, or on those pleasury on these products is equally been Evil; to a cun on vae. if not educated more entially payers\n",
      "Epoch 6 Loss 0.9770\n",
      "Time taken for 1 epoch 41.62122440338135 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.9274590015411377\n",
      "What about economics ?\n",
      "\n",
      "                 [Illustration: Classification, “Statem in the values of Europe\n",
      "    does, therefore and imports with Capital.”(230) It is not a s\n",
      "Epoch 7 Batch 100 Loss 0.9671857953071594\n",
      "What about economics ?)\n",
      "\n",
      "                    Increase.          2. What is extended the French woolen Laws (1881); Eany eighte of\n",
      "      Political Economy,”\n",
      "\n",
      "   12 mhil\n",
      "Epoch 7 Loss 0.9930\n",
      "Time taken for 1 epoch 41.64777326583862 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.8832190036773682\n",
      "What about economics ?\n",
      "\n",
      "150. Different grades of agricultural produce of the demand for the laborers.\n",
      "D 1864 of absiduation as a new extent influen except except for\n",
      "  \n",
      "Epoch 8 Batch 100 Loss 0.950529158115387\n",
      "What about economics ?.. who causes the\n",
      "    four mill£115,000 by an expessive birher, “Stimplian Principles of\n",
      "Period Sténels uf political feelow before, under Gresident,\n",
      "Epoch 8 Loss 0.9438\n",
      "Time taken for 1 epoch 41.656824827194214 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.8833838105201721\n",
      "What about economics ?(52) What out of\n",
      "    them in habit of land d a nationaly later profits entirely\n",
      "somewhat had been evident that high as a banker’s wealth and science\n",
      "Epoch 9 Batch 100 Loss 0.9498996734619141\n",
      "What about economics ?.\n",
      "    160 to 100, 20_s, has effective with the demand (which agriculture capital\n",
      "  to the price would not have been consumed with the new contredito\n",
      "Epoch 9 Loss 0.9278\n",
      "Time taken for 1 epoch 41.60715413093567 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.8251882791519165\n",
      "What about economics ? in\n",
      "    the same amount of more broking at commodities require ascertaineurt.\n",
      "\n",
      "    Foreign basisous 107 of Good, “Giffen, “Traité des Causes    1,3\n",
      "Epoch 10 Batch 100 Loss 0.8957414031028748\n",
      "What about economics ?.. It will be as\n",
      "    digaded, but not question, by fide these gold or showing\n",
      "    employment in price—rises. And of the profit of capital are\n",
      "    c\n",
      "Epoch 10 Loss 0.8843\n",
      "Time taken for 1 epoch 41.6438889503479 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.device('gpu'):\n",
    "    EPOCHS = 10\n",
    "    for epoch in range(EPOCHS):\n",
    "        start_time = time.time()\n",
    "        if epoch > 0:\n",
    "            hidden = model.reset_states()\n",
    "\n",
    "\n",
    "        for (batch_number, (input_data, target_data)) in enumerate(dataset):\n",
    "            loss = train_step(input_data, \n",
    "                              target_data, \n",
    "                              model, \n",
    "                              optimizer,\n",
    "                              train_loss_container)\n",
    "            if batch_number % 100 == 0:\n",
    "                template = 'Epoch {} Batch {} Loss {}'\n",
    "                print(template.format(epoch+1, batch_number, loss))\n",
    "                print(generate_text(model, start_string=u\"What about economics ?\", num_generate=150))\n",
    "        model.save_weights('models/' + model.name + str(EPOCHS) + '_' + str(seq_length))\n",
    "        print ('Epoch {} Loss {:.4f}'.format(epoch+1, loss))\n",
    "        print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start_time))\n",
    "model.save_weights('models/' + model.name + str(EPOCHS) + '_' + str(seq_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What about economics ? Of the question of\r\n",
      "    to generation to send upon them; but those books under the min more than a\r\n",
      "    limit to the laborer’s reason than usual, but first obtained as\r\n",
      "    ttill to essencies at International value. But when the arts are\r\n",
      "    thus bringn from their circumstances into\r\n",
      "    commodities (in the case of a thing; and this between made by\r\n",
      "    the case of slave-lands, ganners; and, as far as a medium is\r\n",
      "    found that it does not bely equaled what is termed a matter\r\n",
      "    with the ga\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"What about economics ?\", num_generate=500))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "37000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 123.33333400000001,
   "position": {
    "height": "40px",
    "left": "769.167px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
